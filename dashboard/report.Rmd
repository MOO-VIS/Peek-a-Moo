---
title: "Preliminary statistical analysis on dairy cows feeding and drinking data"
bibliography: reference.bib
author: "2022 MDS cow-bonds team"
output:
  pdf_document:
    fig_caption: yes        
    includes:  
      in_header: neighbour_report.tex
  html_document:
    toc: true
params:
  data: NA
  cow_id: NA
  date_range: NA

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

# Introduction

Hi, welcome to the statistical analysis part of our shiny app!

The goal of this report is to give an overall idea of the Bayesian methodology and how to implement the analysis using (@R) on the feeding and drinking neighbour count data from `r params$date_range[[1]]` to `r params$date_range[[2]]`. In the data, each observation refers to the number of times that a pair of cows being feeding or drinking neighbours in each day. 


Networks are widely used to investigate the underlying relationships in the cows society. In the neighbour social network plot, nodes represent individual cows and edge width is proportional to the total time of being feeding and drinking neighbours. 

Do cows have their social preference? Do cows have best feeding and drinking buddies and worst enemies? These are the research questions we will try to answer in this report. If you are interested in other regression questions, here is the [repo](https://github.com/UBC-AWP/Bayesian-analysis) that you might want to check out.

The sample size can affect the uncertainty of our estimates. For example, if there is only one observation between a pair of cows in our sample data, intuitively the uncertainty of edge weight between this dyad is larger than the case when the same count has been observed for a hundred of times. If the network estimates are unreliable, this could lead us to draw incorrect conclusions. Therefore, it is necessary to evaluate the uncertainty of the network edge weights.

# Methods

Bootstrapping is a widely used approach for dealing with uncertainty in social networks (@farine2015estimating). The observed data are resampled to create new dataset that are slightly different from the original observations while keeping the same size of network. By repeating the process for hundreds of times and recording the edge weights, we can get a distribution of the edge weights and calculate the 95% confidence interval. However, this method can underestimate the uncertainty and lead to biased estimates when sample sizes are very small (@farine2015estimating). For example, in a limiting case when there is only one observation, the bootstrapping method would draw this value in every sample and conclude the uncertainty is zero. 

Pre-network permutation(also called data stream permutation) is another approach that randomize the network edges while keeping the strength of each node. This method has recently been called into question for its high potential false positive rate with or without observation bias (@sosa2020network) and lead to spurious conclusions as the effect size is not adjusted (@franks2021calculating).

A Bayesian framework for modelling social network data has been introduced (@hart2021bison). In this report, we use the Bayesian framework on the cows feeding and drinking neighbour count data from `r params$date_range[[1]]` to `r params$date_range[[2]]` and calculate the posterior distribution for each edge weight. From the posterior distribution, we can get the 95% credible interval of all the edges that related to our focal cow `r params$cow_id``and infer the focal cow's feeding buddies relationships with other cows in the herd.


```{r library packages, include=FALSE}
rstan_options(auto_write = TRUE)  # To save some compiling
```

# Exploratory Data Analysis

Figure 1 shows the density of the total feeding neighbour counts for all the dyads in the herd from `r params$date_range[[1]]` to `r params$date_range[[2]]`.

```{r prepare data, fig.width=5, fig.height=3, fig.cap="Density plot of edge weights distribution of the cows population", out.width="100%"}

# function to convert the data form to edgelist

combine_data <- function(x){

  edgelist <- x %>%
    group_by(date, from, to) %>%
    summarise(weight = sum(weight), across()) %>%
    ungroup() %>%
    group_by(from, to) %>%
    mutate(dyad_id = cur_group_id(),
           dyad = paste0(from," <-> ",to),
           to = as.integer(to),
           from = as.integer(from),
           weight = as.integer(weight)) %>%
    ungroup() %>%
    tibble()
  # return the edgelist
  edgelist
}

# params <- list()
# params$data <- Feeding_drinking_neighbour_bout
# params$date_range <- list(as.Date("2020-8-1"), as.Date("2020-8-14"))
# params$cow_id <- 4038

df <- combine_data(params$data)

count_df_agg <- df %>%
  group_by(from, to) %>%
  summarise(count_total = sum(weight),
            dyad_id = cur_group_id())


# Plot the density of the observed event counts
plot(density(count_df_agg$count_total), main="", xlab="Dyadic event counts")

```

# Model building

Since the edge weight is the number of counts, we use Poisson distribution as the prior as suggested by previous publication (@hart2021bison). Since we don't have any known observation biases in our data collection, we set the parameters of Poisson distribution to be the edge weight between each dyad.   

$$\text{count}_{ij}^{n} \sim Poisson(W_{ij})$$

where $\text{count}_{ij}^{n}$ represent the number of count of cow $i$ and cow $j$ being feeding and drinking neighbour on the $n$th day, $W_{ij}$ represent the edge weight between cow $i$ and cow $j$.  

# Prior check

Because the Bayesian analysis is impacted by the "correctness" of the prior, it is import to check whether the specified model can be considered reasonable to generate the actual data (@van2021bayesian). Our prior is the Poisson distribution, Figure 2 is the prior distribution without knowing the data.

```{r prior, fig.width=5, fig.height=3, fig.cap="Density plot of prior distribution", out.width="100%"}

  plot(dpois(0:130, lambda = 30), 
       type = "l",
       main="Prior Poisson(lambda = 20)",
       xlab="Dyadic event counts",
       ylab = "Density")

```
# Fit the model

We use Markov Chain Monte Carlo(MCMC) with the parameters: chain = 1, iter = 8000, warmup = 2000, thin = 10 to simulate 600 samples.

```{stan output.var='stan_model'}

data {
  int<lower=0> num_obs; // Number of observations
  int<lower=0> num_dyads; // Number of dyads
  int<lower=0> count[num_obs]; // Count corresponding to each observation 
  int<lower=0> dyad_ids[num_obs]; // Dyad ID corresponding to each data point
}

parameters {
  vector[num_dyads] log_edge; // Log edge weights for each dyad.
}

model {
  for (i in 1:num_obs){
    count[i] ~ poisson(exp(log_edge[dyad_ids[i]]));
  }
}

generated quantities {
  int count_pred[num_obs];
  for (i in 1:num_obs){
  count_pred[i] = poisson_rng(exp(log_edge[dyad_ids[i]]));
  }
}

```

```{r, include=FALSE}

model_data <- list(
  num_obs = nrow(df), # Number of observations
  num_dyads = length(unique(df$dyad_id)), # Number of dyads
  dyad_ids = df$dyad_id, # Vector of dyad IDs corresponding to each observation
  count = df$weight # Vector of event counts corresponding to each observation,
)

posterior_sampling <- rstan::sampling(
  object = stan_model,
  data = model_data,
  chains = 2,
  iter = 8000,
  warmup = 2000,
  thin = 10,
  seed = 123,
  cores = getOption("mc.cores", 2L)
)


```

# Results

The sampling trace can be plotted using Rstan's `traceplot` function to verify this visually and assess convergence. Figure 3 shows that the chains have reached convergence and consistant with each other.

```{r traceplot, fig.width=7, fig.height=4, fig.cap="Traceplot for MCMC chains", out.width="100%"}

rstan::traceplot(posterior_sampling)

```

The posterior distribution can be used to check whether the simulated data from the model resembles the observed data by comparing the density estimates for the simulated data (@gabry2019visualization). Figure 4 shows that posterior prediction fits the data well and the fitting is much better than the prior distribution.

```{r posterior check,  fig.width=5, fig.height=3, fig.cap="Posterior prediction check", out.width="100%"}
# Extract event predictions from the fitted model
count_pred <- rstan::extract(posterior_sampling)$count_pred
num_iterations <- dim(count_pred)[1]

count_df_agg <- df %>%
  group_by(from, to) %>%
  summarise(count_total = sum(weight),
            dyad_id = cur_group_id())

# Plot the density of the observed event counts
plot(density(count_df_agg$count_total), main="", xlab="Dyadic event counts")

# Plot the densities of the predicted event counts, repeat for 20 samples
count_df_copy <- df
for (i in 1:20) {
  count_df_copy$weight <- count_pred[sample(1:num_iterations, size=1), ]
  count_df_agg_copy <- count_df_copy %>% 
    group_by(from, to) %>%
    summarise(count_total = sum(weight))
  lines(density(count_df_agg_copy$count_total), col=rgb(0, 0, 1, 0.5))
}

posterior_sampling_df <- as.data.frame(posterior_sampling)

```

Once we have the posterior distribution for each edge weight, we can compare all the edges weights related to our focal cow `r params$cow_id`. For the simplicity of visualization, Figure 5 only lists the top 10 strongest the weakest relationships related to our focal cow along with 95% credible interval of the edge weights. From the plot, we can have a general idea of which cows are cow `r params$cow_id`'s best feeding buddies.

```{r ranking plot, fig.width=5, fig.height=4, fig.cap="Posterior distribution of edge weights related to focal cow", out.width="100%"}
# We select the edge coefficients related to our focal cow
cow_id = params$cow_id
count_df.focus <- df %>% 
  filter(to == cow_id | from == cow_id) 
ids <- unique(count_df.focus$dyad_id)

posterior_sampling.focus <- posterior_sampling_df[,ids] %>%
  map_df(.,exp)

# We create a new column indicating the replicate by row (1800 in total).
posterior_sampling.focus$sample <- 1:nrow(posterior_sampling.focus)

# Melting the data frame leaving one column for the replicate number (sample),
# another one indicating the team (as log_edge[1], ... log_edge[31]), and
# the continuous posterior count values from our Bayesian sampling.
posterior_sampling.focus <- posterior_sampling.focus %>%
  pivot_longer(-sample, names_to = "dyad", values_to = "count")

# We need the real team codes stored in dictionary_names instead of
# log_edge[1], ... log_edge[31].
posterior_sampling.focus$dyad <- as.factor(posterior_sampling.focus$dyad)

dictionary_names <- count_df.focus %>%
  mutate(dyad_id = paste("log_edge[", as.character(dyad_id), "]", sep = ""))
recoding <- dictionary_names$dyad
names(recoding) <- dictionary_names$dyad_id
levels(posterior_sampling.focus$dyad) <- recode(
  levels(posterior_sampling.focus$dyad),
  !!!recoding
)

posterior_count_CIs <- posterior_sampling.focus %>% 
  group_by(dyad) %>% 
  summarize(lower_bound = quantile(count, probs = 0.025),
            median = median(count),
            upper_bound = quantile(count, probs = 0.975)) %>%
  mutate(dyad = fct_reorder(dyad, median)) %>%
  arrange(desc(median)) %>%
  slice(-(11:(n()-10)))


posterior_count_CIs_plot <- posterior_count_CIs %>%
  ggplot(aes(x = median, y = dyad)) +
  geom_errorbarh(aes(xmax = upper_bound, xmin = lower_bound, color = dyad)) +
  geom_point(color = "blue") +
  theme(
    plot.title = element_text(size = 12, face = "bold"),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 11),
    legend.position = "none"
  ) +
  ggtitle("95% credible intervals by dyad") +
  labs(y = "Dyad", x = "Posterior value of count")

posterior_count_CIs_plot

```



# Conclusion


Bayesian analyses treat each parameter as a random variable and thus inherently account for the uncertainty. We apply the BISoN framework (@hart2021bison) to our feeding and drinking feeding neighbour count data and get the posterior distribution for edge weights. From the edge weights, we can infer the ranking of friendships related our focal cow `r params$cow_id`. We also have applied the Bayesian analysis to other datasets, if you are interested in this topic, please check the code and report in our [repo](https://github.com/UBC-AWP/Bayesian-analysis).



# References


